{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the root directory to the system path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "# Import necessary functions from model.py\n",
    "import importlib\n",
    "from src.model import train_random_forest, train_xgboost, train_lstm, evaluate_model, save_model\n",
    "from src.utils import preprocess_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load your data (assuming train_df and test_df are already preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importlib.reload(src.model)\n",
    "\n",
    "# Example for loading data (you can skip this if data is already loaded)\n",
    "train_data_path = '../data/CMaps/train_FD001.txt'\n",
    "test_data_path = '../data/CMaps/test_FD001.txt'\n",
    "rul_data_path = '../data/CMaps/RUL_FD001.txt'\n",
    "\n",
    "# Create column names\n",
    "col_names = [\n",
    "    'engine_id', 'time_in_cycles', \n",
    "    'operational_setting_1', 'operational_setting_2', 'operational_setting_3'\n",
    "] + [f'sensor_{i}' for i in range(1, 27)]  # This creates sensor_1 to sensor_21\n",
    "\n",
    "# Read the data into pandas dataframes\n",
    "train_df = pd.read_csv(train_data_path, sep=' ', header=None, names=col_names)\n",
    "test_df = pd.read_csv(test_data_path, sep=' ', header=None, names=col_names)\n",
    "rul_df = pd.read_csv(rul_data_path, header=None, names=['RUL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess data (normalization, encoding, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NaN values\n",
    "train_df.dropna(axis=1, how='all', inplace=True)\n",
    "test_df.dropna(axis=1, how='all', inplace=True)\n",
    "\n",
    "# Add RUL values to data\n",
    "test_df['RUL'] = test_df['engine_id'].map(lambda x: rul_df.loc[x - 1, 'RUL'])\n",
    "train_df['RUL'] = train_df['engine_id'].map(lambda x: rul_df.loc[x - 1, 'RUL'])\n",
    "\n",
    "# train_df, test_df = preprocess_data(train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-rmse:41.40210\n",
      "[1]\teval-rmse:41.16507\n",
      "[2]\teval-rmse:41.04990\n",
      "[3]\teval-rmse:41.01928\n",
      "[4]\teval-rmse:40.95461\n",
      "[5]\teval-rmse:40.98197\n",
      "[6]\teval-rmse:40.98020\n",
      "[7]\teval-rmse:41.01046\n",
      "[8]\teval-rmse:41.00811\n",
      "[9]\teval-rmse:41.02626\n",
      "[10]\teval-rmse:41.04439\n",
      "[11]\teval-rmse:41.04784\n",
      "[12]\teval-rmse:41.10469\n",
      "[13]\teval-rmse:41.12859\n",
      "[14]\teval-rmse:41.14795\n",
      "[15]\teval-rmse:41.16565\n",
      "[16]\teval-rmse:41.17014\n",
      "[17]\teval-rmse:41.23583\n",
      "[18]\teval-rmse:41.25310\n",
      "[19]\teval-rmse:41.25674\n",
      "[20]\teval-rmse:41.28022\n",
      "[21]\teval-rmse:41.31827\n",
      "[22]\teval-rmse:41.34931\n",
      "[23]\teval-rmse:41.39355\n",
      "[24]\teval-rmse:41.41230\n",
      "[25]\teval-rmse:41.45475\n",
      "[26]\teval-rmse:41.44801\n",
      "[27]\teval-rmse:41.45946\n",
      "[28]\teval-rmse:41.51802\n",
      "[29]\teval-rmse:41.54504\n",
      "[30]\teval-rmse:41.56192\n",
      "[31]\teval-rmse:41.58399\n",
      "[32]\teval-rmse:41.61107\n",
      "[33]\teval-rmse:41.65905\n",
      "[34]\teval-rmse:41.67317\n",
      "[35]\teval-rmse:41.67754\n",
      "[36]\teval-rmse:41.73702\n",
      "[37]\teval-rmse:41.75877\n",
      "[38]\teval-rmse:41.77945\n",
      "[39]\teval-rmse:41.79709\n",
      "[40]\teval-rmse:41.83025\n",
      "[41]\teval-rmse:41.84325\n",
      "[42]\teval-rmse:41.81786\n",
      "[43]\teval-rmse:41.82763\n",
      "[44]\teval-rmse:41.83575\n",
      "[45]\teval-rmse:41.84236\n",
      "[46]\teval-rmse:41.88114\n",
      "[47]\teval-rmse:41.93459\n",
      "[48]\teval-rmse:41.94277\n",
      "[49]\teval-rmse:41.95981\n",
      "[50]\teval-rmse:41.97048\n",
      "[51]\teval-rmse:41.98329\n",
      "[52]\teval-rmse:41.97796\n",
      "[53]\teval-rmse:42.00651\n",
      "[54]\teval-rmse:42.04250\n",
      "[55]\teval-rmse:42.07262\n",
      "[56]\teval-rmse:42.09263\n",
      "[57]\teval-rmse:42.11778\n",
      "[58]\teval-rmse:42.12209\n",
      "[59]\teval-rmse:42.14052\n",
      "[60]\teval-rmse:42.13570\n",
      "[61]\teval-rmse:42.13456\n",
      "[62]\teval-rmse:42.16726\n",
      "[63]\teval-rmse:42.18810\n",
      "[64]\teval-rmse:42.18740\n",
      "[65]\teval-rmse:42.24510\n",
      "[66]\teval-rmse:42.24376\n",
      "[67]\teval-rmse:42.25286\n",
      "[68]\teval-rmse:42.27453\n",
      "[69]\teval-rmse:42.30851\n",
      "[70]\teval-rmse:42.31408\n",
      "[71]\teval-rmse:42.29274\n",
      "[72]\teval-rmse:42.34085\n",
      "[73]\teval-rmse:42.37506\n",
      "[74]\teval-rmse:42.39225\n",
      "[75]\teval-rmse:42.38378\n",
      "[76]\teval-rmse:42.41399\n",
      "[77]\teval-rmse:42.44187\n",
      "[78]\teval-rmse:42.46513\n",
      "[79]\teval-rmse:42.46507\n",
      "[80]\teval-rmse:42.49167\n",
      "[81]\teval-rmse:42.51071\n",
      "[82]\teval-rmse:42.50048\n",
      "[83]\teval-rmse:42.51172\n",
      "[84]\teval-rmse:42.52093\n",
      "[85]\teval-rmse:42.55401\n",
      "[86]\teval-rmse:42.56037\n",
      "[87]\teval-rmse:42.57748\n",
      "[88]\teval-rmse:42.59047\n",
      "[89]\teval-rmse:42.60144\n",
      "[90]\teval-rmse:42.60833\n",
      "[91]\teval-rmse:42.62164\n",
      "[92]\teval-rmse:42.64710\n",
      "[93]\teval-rmse:42.69259\n",
      "[94]\teval-rmse:42.72716\n",
      "[95]\teval-rmse:42.74570\n",
      "[96]\teval-rmse:42.73303\n",
      "[97]\teval-rmse:42.74908\n",
      "[98]\teval-rmse:42.77344\n",
      "[99]\teval-rmse:42.79381\n",
      "Epoch 1/10\n",
      "516/516 [==============================] - 4s 3ms/step - loss: 6966.0332\n",
      "Epoch 2/10\n",
      "516/516 [==============================] - 1s 3ms/step - loss: 6029.6260\n",
      "Epoch 3/10\n",
      "516/516 [==============================] - 1s 3ms/step - loss: 5220.5879\n",
      "Epoch 4/10\n",
      "516/516 [==============================] - 1s 3ms/step - loss: 4526.7837\n",
      "Epoch 5/10\n",
      "516/516 [==============================] - 1s 3ms/step - loss: 3940.9983\n",
      "Epoch 6/10\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 3437.9856\n",
      "Epoch 7/10\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 3020.6221\n",
      "Epoch 8/10\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 2681.5994\n",
      "Epoch 9/10\n",
      "516/516 [==============================] - 1s 3ms/step - loss: 2419.9248\n",
      "Epoch 10/10\n",
      "516/516 [==============================] - 1s 2ms/step - loss: 2202.9102\n",
      "129/129 [==============================] - 1s 1ms/step\n",
      "Random Forest - MAE: 35.718526774897015, RMSE: 41.19672796130431\n",
      "XGBoost - MAE: 36.57940071019648, RMSE: 42.79380700308592\n",
      "LSTM - MAE: 40.11019147369629, RMSE: 45.369288857503385\n"
     ]
    }
   ],
   "source": [
    "# Define features and target variable\n",
    "X = train_df.drop(columns=['RUL', 'engine_id', 'time_in_cycles'])  # Features (drop non-feature columns) - all columns except the target column\n",
    "y = train_df['RUL']  # Target (RUL)\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\"Train Random Forest Model\"\n",
    "rf_model = train_random_forest(X_train, y_train)\n",
    "\n",
    "# Train XGBoost Model\n",
    "xgb_model, dval = train_xgboost(X_train, X_val, y_train, y_val)\n",
    "\n",
    "# Train LSTM Model (reshape for LSTM input)\n",
    "# X_train_lstm = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "# X_val_lstm = X_val.reshape((X_val.shape[0], 1, X_val.shape[1]))\n",
    "lstm_model = train_lstm(X_train, y_train)\n",
    "\n",
    "# Evaluate Models\n",
    "rf_mae, rf_rmse = evaluate_model(rf_model, X_val, y_val)\n",
    "xgb_mae, xgb_rmse = evaluate_model(xgb_model, dval, y_val)\n",
    "lstm_mae, lstm_rmse = evaluate_model(lstm_model, X_val, y_val)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Random Forest - MAE: {rf_mae}, RMSE: {rf_rmse}\")\n",
    "print(f\"XGBoost - MAE: {xgb_mae}, RMSE: {xgb_rmse}\")\n",
    "print(f\"LSTM - MAE: {lstm_mae}, RMSE: {lstm_rmse}\")\n",
    "\n",
    "# Save the best model (e.g., Random Forest in this case)\n",
    "# save_model(rf_model, 'random_forest_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
