{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.   FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set default Seaborn style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = '../data/CMaps/train_FD001.txt'\n",
    "test_data_path = '../data/CMaps/test_FD001.txt'\n",
    "rul_data_path = '../data/CMaps/RUL_FD001.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define column names based on the dataset's structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\n",
    "    'engine_id', 'time_in_cycles', \n",
    "    'operational_setting_1', 'operational_setting_2', 'operational_setting_3'\n",
    "] + [f'sensor_{i}' for i in range(1, 27)]  # This creates sensor_1 to sensor_21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(train_data_path, sep=' ', header=None, names=col_names)\n",
    "test_df = pd.read_csv(test_data_path, sep=' ', header=None, names=col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the shape of dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the train dataframe is:  (20631, 31)\n",
      "The shape of the test dataframe is:  (20631, 31)\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of the train dataframe is: \", train_df.shape)\n",
    "print(\"The shape of the test dataframe is: \", train_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns that are completely empty (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(axis=1, how='all', inplace=True)\n",
    "test_df.dropna(axis=1, how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if shape has changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the train dataframe is:  (20631, 26)\n",
      "The shape of the test dataframe is:  (20631, 26)\n"
     ]
    }
   ],
   "source": [
    "print(\"The shape of the train dataframe is: \", train_df.shape)\n",
    "print(\"The shape of the test dataframe is: \", train_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Remaining Useful Life (RUL) data for the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rul_df = pd.read_csv(rul_data_path, header=None, names=['RUL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RUL\n",
       "0  112\n",
       "1   98\n",
       "2   69\n",
       "3   82\n",
       "4   91"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rul_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add RUL values to the test dataframe\n",
    "Since the RUL values correspond to each engine in the test set, we add them directly to the test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['RUL'] = test_df['engine_id'].map(lambda x: rul_df.loc[x - 1, 'RUL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for each engine, the RUL value is the same for all cycles but corresponds to the final cycle for that engine.\n",
    "Let's verify the first few rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engine_id</th>\n",
       "      <th>time_in_cycles</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   engine_id  time_in_cycles  RUL\n",
       "0          1               1  112\n",
       "1          1               2  112\n",
       "2          1               3  112\n",
       "3          1               4  112\n",
       "4          1               5  112"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[['engine_id', 'time_in_cycles', 'RUL']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engine_id</th>\n",
       "      <th>time_in_cycles</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13091</th>\n",
       "      <td>100</td>\n",
       "      <td>194</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13092</th>\n",
       "      <td>100</td>\n",
       "      <td>195</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13093</th>\n",
       "      <td>100</td>\n",
       "      <td>196</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13094</th>\n",
       "      <td>100</td>\n",
       "      <td>197</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13095</th>\n",
       "      <td>100</td>\n",
       "      <td>198</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       engine_id  time_in_cycles  RUL\n",
       "13091        100             194   20\n",
       "13092        100             195   20\n",
       "13093        100             196   20\n",
       "13094        100             197   20\n",
       "13095        100             198   20"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[['engine_id', 'time_in_cycles', 'RUL']].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each cycle for an engine will have the same RUL value that corresponds to the remaining cycles for that engine, starting from the last recorded cycle in the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Rolling Statistics\n",
    "\n",
    "Let's create rolling means and rolling standard deviations for each sensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 5  # Set the window size for rolling calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Create rolling mean and rolling std for each sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sensor in [f'sensor_{i}' for i in range(1, 22)]:\n",
    "    train_df[f'{sensor}_rolling_mean'] = train_df[sensor].rolling(window=window_size).mean()\n",
    "    train_df[f'{sensor}_rolling_std'] = train_df[sensor].rolling(window=window_size).std()\n",
    "    test_df[f'{sensor}_rolling_mean'] = test_df[sensor].rolling(window=window_size).mean()\n",
    "    test_df[f'{sensor}_rolling_std'] = test_df[sensor].rolling(window=window_size).std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop NaN values that result from the rolling mean and std calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(inplace=True)\n",
    "test_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the first few rows to ensure the features have been added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engine_id</th>\n",
       "      <th>time_in_cycles</th>\n",
       "      <th>sensor_2</th>\n",
       "      <th>sensor_2_rolling_mean</th>\n",
       "      <th>sensor_2_rolling_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>642.37</td>\n",
       "      <td>642.208</td>\n",
       "      <td>0.234776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>642.10</td>\n",
       "      <td>642.264</td>\n",
       "      <td>0.128374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>642.48</td>\n",
       "      <td>642.330</td>\n",
       "      <td>0.139463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>642.56</td>\n",
       "      <td>642.372</td>\n",
       "      <td>0.174270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>642.12</td>\n",
       "      <td>642.326</td>\n",
       "      <td>0.208519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   engine_id  time_in_cycles  sensor_2  sensor_2_rolling_mean  \\\n",
       "4          1               5    642.37                642.208   \n",
       "5          1               6    642.10                642.264   \n",
       "6          1               7    642.48                642.330   \n",
       "7          1               8    642.56                642.372   \n",
       "8          1               9    642.12                642.326   \n",
       "\n",
       "   sensor_2_rolling_std  \n",
       "4              0.234776  \n",
       "5              0.128374  \n",
       "6              0.139463  \n",
       "7              0.174270  \n",
       "8              0.208519  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['engine_id', 'time_in_cycles', 'sensor_2', 'sensor_2_rolling_mean', 'sensor_2_rolling_std']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Delta Features (Difference between Consecutive Cycles)\n",
    "Calculate the delta (difference) between consecutive cycles for each sensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sensor in [f'sensor_{i}' for i in range(1, 22)]:\n",
    "    train_df[f'{sensor}_delta'] = train_df[sensor] - train_df.groupby('engine_id')[sensor].shift(1)\n",
    "    test_df[f'{sensor}_delta'] = test_df[sensor] - test_df.groupby('engine_id')[sensor].shift(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop NaN values resulting from the shift operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(inplace=True)\n",
    "test_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the first few rows to ensure the delta features have been added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engine_id</th>\n",
       "      <th>time_in_cycles</th>\n",
       "      <th>sensor_2</th>\n",
       "      <th>sensor_2_delta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>642.10</td>\n",
       "      <td>-0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>642.48</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>642.56</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>642.12</td>\n",
       "      <td>-0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>641.71</td>\n",
       "      <td>-0.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   engine_id  time_in_cycles  sensor_2  sensor_2_delta\n",
       "5          1               6    642.10           -0.27\n",
       "6          1               7    642.48            0.38\n",
       "7          1               8    642.56            0.08\n",
       "8          1               9    642.12           -0.44\n",
       "9          1              10    641.71           -0.41"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['engine_id', 'time_in_cycles', 'sensor_2', 'sensor_2_delta']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Cumulative Features (Cumulative Sum and Mean)\n",
    "Create cumulative sum and cumulative mean for each sensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\1281283644.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_cummean'] = train_df[sensor].expanding().mean()\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\1281283644.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_cumsum'] = test_df[sensor].cumsum()\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\1281283644.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_cummean'] = test_df[sensor].expanding().mean()\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\1281283644.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_cumsum'] = train_df[sensor].cumsum()\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\1281283644.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_cummean'] = train_df[sensor].expanding().mean()\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\1281283644.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_cumsum'] = test_df[sensor].cumsum()\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\1281283644.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_cummean'] = test_df[sensor].expanding().mean()\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\1281283644.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_cumsum'] = train_df[sensor].cumsum()\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\1281283644.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_cummean'] = train_df[sensor].expanding().mean()\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\1281283644.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_cumsum'] = test_df[sensor].cumsum()\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\1281283644.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_cummean'] = test_df[sensor].expanding().mean()\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\1281283644.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_cumsum'] = train_df[sensor].cumsum()\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\1281283644.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_cummean'] = train_df[sensor].expanding().mean()\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\1281283644.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_cumsum'] = test_df[sensor].cumsum()\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\1281283644.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_cummean'] = test_df[sensor].expanding().mean()\n"
     ]
    }
   ],
   "source": [
    "for sensor in [f'sensor_{i}' for i in range(1, 22)]:\n",
    "    train_df[f'{sensor}_cumsum'] = train_df[sensor].cumsum()\n",
    "    train_df[f'{sensor}_cummean'] = train_df[sensor].expanding().mean()\n",
    "    test_df[f'{sensor}_cumsum'] = test_df[sensor].cumsum()\n",
    "    test_df[f'{sensor}_cummean'] = test_df[sensor].expanding().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the first few rows to ensure the cumulative features have been added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engine_id</th>\n",
       "      <th>time_in_cycles</th>\n",
       "      <th>sensor_2</th>\n",
       "      <th>sensor_2_cumsum</th>\n",
       "      <th>sensor_2_cummean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>642.10</td>\n",
       "      <td>642.10</td>\n",
       "      <td>642.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>642.48</td>\n",
       "      <td>1284.58</td>\n",
       "      <td>642.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>642.56</td>\n",
       "      <td>1927.14</td>\n",
       "      <td>642.380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>642.12</td>\n",
       "      <td>2569.26</td>\n",
       "      <td>642.315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>641.71</td>\n",
       "      <td>3210.97</td>\n",
       "      <td>642.194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   engine_id  time_in_cycles  sensor_2  sensor_2_cumsum  sensor_2_cummean\n",
       "5          1               6    642.10           642.10           642.100\n",
       "6          1               7    642.48          1284.58           642.290\n",
       "7          1               8    642.56          1927.14           642.380\n",
       "8          1               9    642.12          2569.26           642.315\n",
       "9          1              10    641.71          3210.97           642.194"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['engine_id', 'time_in_cycles', 'sensor_2', 'sensor_2_cumsum', 'sensor_2_cummean']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Lag Features (Values from Previous Cycles)\n",
    "Create lag features that capture previous cycle values. Let's capture values from the previous cycle for each sensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_lag_1'] = train_df.groupby('engine_id')[sensor].shift(1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_lag_1'] = test_df.groupby('engine_id')[sensor].shift(1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_lag_1'] = train_df.groupby('engine_id')[sensor].shift(1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_lag_1'] = test_df.groupby('engine_id')[sensor].shift(1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_lag_1'] = train_df.groupby('engine_id')[sensor].shift(1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_lag_1'] = test_df.groupby('engine_id')[sensor].shift(1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_lag_1'] = train_df.groupby('engine_id')[sensor].shift(1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_lag_1'] = test_df.groupby('engine_id')[sensor].shift(1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_lag_1'] = train_df.groupby('engine_id')[sensor].shift(1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_lag_1'] = test_df.groupby('engine_id')[sensor].shift(1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_lag_1'] = train_df.groupby('engine_id')[sensor].shift(1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_lag_1'] = test_df.groupby('engine_id')[sensor].shift(1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_lag_1'] = train_df.groupby('engine_id')[sensor].shift(1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_lag_1'] = test_df.groupby('engine_id')[sensor].shift(1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_lag_1'] = train_df.groupby('engine_id')[sensor].shift(1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_lag_1'] = test_df.groupby('engine_id')[sensor].shift(1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_lag_1'] = train_df.groupby('engine_id')[sensor].shift(1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_lag_1'] = test_df.groupby('engine_id')[sensor].shift(1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_lag_1'] = train_df.groupby('engine_id')[sensor].shift(1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_lag_1'] = test_df.groupby('engine_id')[sensor].shift(1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_lag_1'] = train_df.groupby('engine_id')[sensor].shift(1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_lag_1'] = test_df.groupby('engine_id')[sensor].shift(1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_lag_1'] = train_df.groupby('engine_id')[sensor].shift(1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_lag_1'] = test_df.groupby('engine_id')[sensor].shift(1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_lag_1'] = train_df.groupby('engine_id')[sensor].shift(1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_lag_1'] = test_df.groupby('engine_id')[sensor].shift(1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_lag_1'] = train_df.groupby('engine_id')[sensor].shift(1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_lag_1'] = test_df.groupby('engine_id')[sensor].shift(1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_lag_1'] = train_df.groupby('engine_id')[sensor].shift(1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_lag_1'] = test_df.groupby('engine_id')[sensor].shift(1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_lag_1'] = train_df.groupby('engine_id')[sensor].shift(1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_lag_1'] = test_df.groupby('engine_id')[sensor].shift(1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_lag_1'] = train_df.groupby('engine_id')[sensor].shift(1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_lag_1'] = test_df.groupby('engine_id')[sensor].shift(1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_lag_1'] = train_df.groupby('engine_id')[sensor].shift(1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_lag_1'] = test_df.groupby('engine_id')[sensor].shift(1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_lag_1'] = train_df.groupby('engine_id')[sensor].shift(1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_lag_1'] = test_df.groupby('engine_id')[sensor].shift(1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_lag_1'] = train_df.groupby('engine_id')[sensor].shift(1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_lag_1'] = test_df.groupby('engine_id')[sensor].shift(1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_lag_1'] = train_df.groupby('engine_id')[sensor].shift(1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\3427809972.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_lag_1'] = test_df.groupby('engine_id')[sensor].shift(1)\n"
     ]
    }
   ],
   "source": [
    "for sensor in [f'sensor_{i}' for i in range(1, 22)]:\n",
    "    train_df[f'{sensor}_lag_1'] = train_df.groupby('engine_id')[sensor].shift(1)\n",
    "    test_df[f'{sensor}_lag_1'] = test_df.groupby('engine_id')[sensor].shift(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop NaN values that result from the lag features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(inplace=True)\n",
    "test_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the first few rows to ensure the lag features have been added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engine_id</th>\n",
       "      <th>time_in_cycles</th>\n",
       "      <th>sensor_2</th>\n",
       "      <th>sensor_2_lag_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>642.48</td>\n",
       "      <td>642.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>642.56</td>\n",
       "      <td>642.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>642.12</td>\n",
       "      <td>642.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>641.71</td>\n",
       "      <td>642.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>642.28</td>\n",
       "      <td>641.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    engine_id  time_in_cycles  sensor_2  sensor_2_lag_1\n",
       "6           1               7    642.48          642.10\n",
       "7           1               8    642.56          642.48\n",
       "8           1               9    642.12          642.56\n",
       "9           1              10    641.71          642.12\n",
       "10          1              11    642.28          641.71"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['engine_id', 'time_in_cycles', 'sensor_2', 'sensor_2_lag_1']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Rolling Percentile (Additional transformation)\n",
    "Calculate rolling percentiles (e.g., 10th and 90th percentile) for each sensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_10th'] = train_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_90th'] = train_df[sensor].rolling(window=window_size).quantile(0.9)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_10th'] = test_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_90th'] = test_df[sensor].rolling(window=window_size).quantile(0.9)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_10th'] = train_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_90th'] = train_df[sensor].rolling(window=window_size).quantile(0.9)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_10th'] = test_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_90th'] = test_df[sensor].rolling(window=window_size).quantile(0.9)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_10th'] = train_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_90th'] = train_df[sensor].rolling(window=window_size).quantile(0.9)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_10th'] = test_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_90th'] = test_df[sensor].rolling(window=window_size).quantile(0.9)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_10th'] = train_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_90th'] = train_df[sensor].rolling(window=window_size).quantile(0.9)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_10th'] = test_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_90th'] = test_df[sensor].rolling(window=window_size).quantile(0.9)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_10th'] = train_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_90th'] = train_df[sensor].rolling(window=window_size).quantile(0.9)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_10th'] = test_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_90th'] = test_df[sensor].rolling(window=window_size).quantile(0.9)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_10th'] = train_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_90th'] = train_df[sensor].rolling(window=window_size).quantile(0.9)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_10th'] = test_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_90th'] = test_df[sensor].rolling(window=window_size).quantile(0.9)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_10th'] = train_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_90th'] = train_df[sensor].rolling(window=window_size).quantile(0.9)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_10th'] = test_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_90th'] = test_df[sensor].rolling(window=window_size).quantile(0.9)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_10th'] = train_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_90th'] = train_df[sensor].rolling(window=window_size).quantile(0.9)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_10th'] = test_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_90th'] = test_df[sensor].rolling(window=window_size).quantile(0.9)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_10th'] = train_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_90th'] = train_df[sensor].rolling(window=window_size).quantile(0.9)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_10th'] = test_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_90th'] = test_df[sensor].rolling(window=window_size).quantile(0.9)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_10th'] = train_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_90th'] = train_df[sensor].rolling(window=window_size).quantile(0.9)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_10th'] = test_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_90th'] = test_df[sensor].rolling(window=window_size).quantile(0.9)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_10th'] = train_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_90th'] = train_df[sensor].rolling(window=window_size).quantile(0.9)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_10th'] = test_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_90th'] = test_df[sensor].rolling(window=window_size).quantile(0.9)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_10th'] = train_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_90th'] = train_df[sensor].rolling(window=window_size).quantile(0.9)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_10th'] = test_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_90th'] = test_df[sensor].rolling(window=window_size).quantile(0.9)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_10th'] = train_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_90th'] = train_df[sensor].rolling(window=window_size).quantile(0.9)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_10th'] = test_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_90th'] = test_df[sensor].rolling(window=window_size).quantile(0.9)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_10th'] = train_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_90th'] = train_df[sensor].rolling(window=window_size).quantile(0.9)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_10th'] = test_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_90th'] = test_df[sensor].rolling(window=window_size).quantile(0.9)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_10th'] = train_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_90th'] = train_df[sensor].rolling(window=window_size).quantile(0.9)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_10th'] = test_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_90th'] = test_df[sensor].rolling(window=window_size).quantile(0.9)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_10th'] = train_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_90th'] = train_df[sensor].rolling(window=window_size).quantile(0.9)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_10th'] = test_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_90th'] = test_df[sensor].rolling(window=window_size).quantile(0.9)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_10th'] = train_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_90th'] = train_df[sensor].rolling(window=window_size).quantile(0.9)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_10th'] = test_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_90th'] = test_df[sensor].rolling(window=window_size).quantile(0.9)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_10th'] = train_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_90th'] = train_df[sensor].rolling(window=window_size).quantile(0.9)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_10th'] = test_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_90th'] = test_df[sensor].rolling(window=window_size).quantile(0.9)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_10th'] = train_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_90th'] = train_df[sensor].rolling(window=window_size).quantile(0.9)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_10th'] = test_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_90th'] = test_df[sensor].rolling(window=window_size).quantile(0.9)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_10th'] = train_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_90th'] = train_df[sensor].rolling(window=window_size).quantile(0.9)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_10th'] = test_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_90th'] = test_df[sensor].rolling(window=window_size).quantile(0.9)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_10th'] = train_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f'{sensor}_rolling_90th'] = train_df[sensor].rolling(window=window_size).quantile(0.9)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:4: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_10th'] = test_df[sensor].rolling(window=window_size).quantile(0.1)\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2826385385.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df[f'{sensor}_rolling_90th'] = test_df[sensor].rolling(window=window_size).quantile(0.9)\n"
     ]
    }
   ],
   "source": [
    "for sensor in [f'sensor_{i}' for i in range(1, 22)]:\n",
    "    train_df[f'{sensor}_rolling_10th'] = train_df[sensor].rolling(window=window_size).quantile(0.1)\n",
    "    train_df[f'{sensor}_rolling_90th'] = train_df[sensor].rolling(window=window_size).quantile(0.9)\n",
    "    test_df[f'{sensor}_rolling_10th'] = test_df[sensor].rolling(window=window_size).quantile(0.1)\n",
    "    test_df[f'{sensor}_rolling_90th'] = test_df[sensor].rolling(window=window_size).quantile(0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop NaN values resulting from the rolling percentile calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.dropna(inplace=True)\n",
    "test_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the first few rows to ensure the rolling percentiles have been added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engine_id</th>\n",
       "      <th>time_in_cycles</th>\n",
       "      <th>sensor_2</th>\n",
       "      <th>sensor_2_rolling_10th</th>\n",
       "      <th>sensor_2_rolling_90th</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>642.28</td>\n",
       "      <td>641.874</td>\n",
       "      <td>642.528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>642.06</td>\n",
       "      <td>641.850</td>\n",
       "      <td>642.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>643.07</td>\n",
       "      <td>641.850</td>\n",
       "      <td>642.754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>642.35</td>\n",
       "      <td>641.850</td>\n",
       "      <td>642.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>642.43</td>\n",
       "      <td>642.148</td>\n",
       "      <td>642.814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    engine_id  time_in_cycles  sensor_2  sensor_2_rolling_10th  \\\n",
       "10          1              11    642.28                641.874   \n",
       "11          1              12    642.06                641.850   \n",
       "12          1              13    643.07                641.850   \n",
       "13          1              14    642.35                641.850   \n",
       "14          1              15    642.43                642.148   \n",
       "\n",
       "    sensor_2_rolling_90th  \n",
       "10                642.528  \n",
       "11                642.448  \n",
       "12                642.754  \n",
       "13                642.782  \n",
       "14                642.814  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['engine_id', 'time_in_cycles', 'sensor_2', 'sensor_2_rolling_10th', 'sensor_2_rolling_90th']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. Feature Interaction (Product of sensors)\n",
    "You can also create new features by interacting different sensor values. For example, you could take the product of two sensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2508984821.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df['sensor_1_sensor_2_interaction'] = train_df['sensor_1'] * train_df['sensor_2']\n",
      "C:\\Users\\amurd\\AppData\\Local\\Temp\\ipykernel_62428\\2508984821.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  test_df['sensor_1_sensor_2_interaction'] = test_df['sensor_1'] * test_df['sensor_2']\n"
     ]
    }
   ],
   "source": [
    "train_df['sensor_1_sensor_2_interaction'] = train_df['sensor_1'] * train_df['sensor_2']\n",
    "test_df['sensor_1_sensor_2_interaction'] = test_df['sensor_1'] * test_df['sensor_2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the first few rows to ensure the interaction feature has been added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engine_id</th>\n",
       "      <th>time_in_cycles</th>\n",
       "      <th>sensor_1</th>\n",
       "      <th>sensor_2</th>\n",
       "      <th>sensor_1_sensor_2_interaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.28</td>\n",
       "      <td>333131.3676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.06</td>\n",
       "      <td>333017.2602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.07</td>\n",
       "      <td>333541.1169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>333167.6745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.43</td>\n",
       "      <td>333209.1681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    engine_id  time_in_cycles  sensor_1  sensor_2  \\\n",
       "10          1              11    518.67    642.28   \n",
       "11          1              12    518.67    642.06   \n",
       "12          1              13    518.67    643.07   \n",
       "13          1              14    518.67    642.35   \n",
       "14          1              15    518.67    642.43   \n",
       "\n",
       "    sensor_1_sensor_2_interaction  \n",
       "10                    333131.3676  \n",
       "11                    333017.2602  \n",
       "12                    333541.1169  \n",
       "13                    333167.6745  \n",
       "14                    333209.1681  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[['engine_id', 'time_in_cycles', 'sensor_1', 'sensor_2', 'sensor_1_sensor_2_interaction']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of engineered features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engine_id</th>\n",
       "      <th>time_in_cycles</th>\n",
       "      <th>operational_setting_1</th>\n",
       "      <th>operational_setting_2</th>\n",
       "      <th>operational_setting_3</th>\n",
       "      <th>sensor_1</th>\n",
       "      <th>sensor_2</th>\n",
       "      <th>sensor_3</th>\n",
       "      <th>sensor_4</th>\n",
       "      <th>sensor_5</th>\n",
       "      <th>...</th>\n",
       "      <th>sensor_17_rolling_90th</th>\n",
       "      <th>sensor_18_rolling_10th</th>\n",
       "      <th>sensor_18_rolling_90th</th>\n",
       "      <th>sensor_19_rolling_10th</th>\n",
       "      <th>sensor_19_rolling_90th</th>\n",
       "      <th>sensor_20_rolling_10th</th>\n",
       "      <th>sensor_20_rolling_90th</th>\n",
       "      <th>sensor_21_rolling_10th</th>\n",
       "      <th>sensor_21_rolling_90th</th>\n",
       "      <th>sensor_1_sensor_2_interaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20423.000000</td>\n",
       "      <td>20423.000000</td>\n",
       "      <td>20423.000000</td>\n",
       "      <td>20423.000000</td>\n",
       "      <td>20423.0</td>\n",
       "      <td>2.042300e+04</td>\n",
       "      <td>20423.000000</td>\n",
       "      <td>20423.000000</td>\n",
       "      <td>20423.000000</td>\n",
       "      <td>2.042300e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>20423.000000</td>\n",
       "      <td>20423.0</td>\n",
       "      <td>20423.0</td>\n",
       "      <td>20423.0</td>\n",
       "      <td>20423.0</td>\n",
       "      <td>20423.000000</td>\n",
       "      <td>20423.000000</td>\n",
       "      <td>20423.000000</td>\n",
       "      <td>20423.000000</td>\n",
       "      <td>20423.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>51.536209</td>\n",
       "      <td>109.898791</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.186700e+02</td>\n",
       "      <td>642.684118</td>\n",
       "      <td>1590.561123</td>\n",
       "      <td>1408.999687</td>\n",
       "      <td>1.462000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>394.055496</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.721022</td>\n",
       "      <td>38.908600</td>\n",
       "      <td>23.232931</td>\n",
       "      <td>23.344809</td>\n",
       "      <td>333340.971688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>29.219596</td>\n",
       "      <td>68.372872</td>\n",
       "      <td>0.002188</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.525784e-11</td>\n",
       "      <td>0.500361</td>\n",
       "      <td>6.132682</td>\n",
       "      <td>9.000270</td>\n",
       "      <td>3.382266e-12</td>\n",
       "      <td>...</td>\n",
       "      <td>1.350983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.160895</td>\n",
       "      <td>0.155586</td>\n",
       "      <td>0.096134</td>\n",
       "      <td>0.093711</td>\n",
       "      <td>259.522156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-0.008700</td>\n",
       "      <td>-0.000600</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.186700e+02</td>\n",
       "      <td>641.210000</td>\n",
       "      <td>1571.040000</td>\n",
       "      <td>1382.250000</td>\n",
       "      <td>1.462000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>390.600000</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.188000</td>\n",
       "      <td>38.392000</td>\n",
       "      <td>22.938640</td>\n",
       "      <td>23.031320</td>\n",
       "      <td>332576.390700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>-0.001500</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.186700e+02</td>\n",
       "      <td>642.330000</td>\n",
       "      <td>1586.310000</td>\n",
       "      <td>1402.420000</td>\n",
       "      <td>1.462000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>393.000000</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.622000</td>\n",
       "      <td>38.814000</td>\n",
       "      <td>23.173950</td>\n",
       "      <td>23.286860</td>\n",
       "      <td>333157.301100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.186700e+02</td>\n",
       "      <td>642.650000</td>\n",
       "      <td>1590.140000</td>\n",
       "      <td>1408.100000</td>\n",
       "      <td>1.462000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.740000</td>\n",
       "      <td>38.924000</td>\n",
       "      <td>23.243300</td>\n",
       "      <td>23.353800</td>\n",
       "      <td>333323.275500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.186700e+02</td>\n",
       "      <td>643.010000</td>\n",
       "      <td>1594.420000</td>\n",
       "      <td>1414.630000</td>\n",
       "      <td>1.462000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.840000</td>\n",
       "      <td>39.026000</td>\n",
       "      <td>23.303200</td>\n",
       "      <td>23.413680</td>\n",
       "      <td>333509.996700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>362.000000</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.186700e+02</td>\n",
       "      <td>644.530000</td>\n",
       "      <td>1616.910000</td>\n",
       "      <td>1441.490000</td>\n",
       "      <td>1.462000e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>398.800000</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.150000</td>\n",
       "      <td>39.334000</td>\n",
       "      <td>23.459840</td>\n",
       "      <td>23.594580</td>\n",
       "      <td>334298.375100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          engine_id  time_in_cycles  operational_setting_1  \\\n",
       "count  20423.000000    20423.000000           20423.000000   \n",
       "mean      51.536209      109.898791              -0.000008   \n",
       "std       29.219596       68.372872               0.002188   \n",
       "min        1.000000        3.000000              -0.008700   \n",
       "25%       26.000000       54.000000              -0.001500   \n",
       "50%       52.000000      105.000000               0.000000   \n",
       "75%       77.000000      157.000000               0.001500   \n",
       "max      100.000000      362.000000               0.008700   \n",
       "\n",
       "       operational_setting_2  operational_setting_3      sensor_1  \\\n",
       "count           20423.000000                20423.0  2.042300e+04   \n",
       "mean                0.000002                  100.0  5.186700e+02   \n",
       "std                 0.000293                    0.0  6.525784e-11   \n",
       "min                -0.000600                  100.0  5.186700e+02   \n",
       "25%                -0.000200                  100.0  5.186700e+02   \n",
       "50%                 0.000000                  100.0  5.186700e+02   \n",
       "75%                 0.000300                  100.0  5.186700e+02   \n",
       "max                 0.000600                  100.0  5.186700e+02   \n",
       "\n",
       "           sensor_2      sensor_3      sensor_4      sensor_5  ...  \\\n",
       "count  20423.000000  20423.000000  20423.000000  2.042300e+04  ...   \n",
       "mean     642.684118   1590.561123   1408.999687  1.462000e+01  ...   \n",
       "std        0.500361      6.132682      9.000270  3.382266e-12  ...   \n",
       "min      641.210000   1571.040000   1382.250000  1.462000e+01  ...   \n",
       "25%      642.330000   1586.310000   1402.420000  1.462000e+01  ...   \n",
       "50%      642.650000   1590.140000   1408.100000  1.462000e+01  ...   \n",
       "75%      643.010000   1594.420000   1414.630000  1.462000e+01  ...   \n",
       "max      644.530000   1616.910000   1441.490000  1.462000e+01  ...   \n",
       "\n",
       "       sensor_17_rolling_90th  sensor_18_rolling_10th  sensor_18_rolling_90th  \\\n",
       "count            20423.000000                 20423.0                 20423.0   \n",
       "mean               394.055496                  2388.0                  2388.0   \n",
       "std                  1.350983                     0.0                     0.0   \n",
       "min                390.600000                  2388.0                  2388.0   \n",
       "25%                393.000000                  2388.0                  2388.0   \n",
       "50%                394.000000                  2388.0                  2388.0   \n",
       "75%                395.000000                  2388.0                  2388.0   \n",
       "max                398.800000                  2388.0                  2388.0   \n",
       "\n",
       "       sensor_19_rolling_10th  sensor_19_rolling_90th  sensor_20_rolling_10th  \\\n",
       "count                 20423.0                 20423.0            20423.000000   \n",
       "mean                    100.0                   100.0               38.721022   \n",
       "std                       0.0                     0.0                0.160895   \n",
       "min                     100.0                   100.0               38.188000   \n",
       "25%                     100.0                   100.0               38.622000   \n",
       "50%                     100.0                   100.0               38.740000   \n",
       "75%                     100.0                   100.0               38.840000   \n",
       "max                     100.0                   100.0               39.150000   \n",
       "\n",
       "       sensor_20_rolling_90th  sensor_21_rolling_10th  sensor_21_rolling_90th  \\\n",
       "count            20423.000000            20423.000000            20423.000000   \n",
       "mean                38.908600               23.232931               23.344809   \n",
       "std                  0.155586                0.096134                0.093711   \n",
       "min                 38.392000               22.938640               23.031320   \n",
       "25%                 38.814000               23.173950               23.286860   \n",
       "50%                 38.924000               23.243300               23.353800   \n",
       "75%                 39.026000               23.303200               23.413680   \n",
       "max                 39.334000               23.459840               23.594580   \n",
       "\n",
       "       sensor_1_sensor_2_interaction  \n",
       "count                   20423.000000  \n",
       "mean                   333340.971688  \n",
       "std                       259.522156  \n",
       "min                    332576.390700  \n",
       "25%                    333157.301100  \n",
       "50%                    333323.275500  \n",
       "75%                    333509.996700  \n",
       "max                    334298.375100  \n",
       "\n",
       "[8 rows x 195 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pm-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
